{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test verilerini manuel accuracy hesaplama için hazırlama\n",
        "\n",
        "import tensorflow\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Input, Embedding, Reshape, LSTM, Dense, Flatten, Bidirectional, Concatenate\n",
        "from keras.models import Model\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "\n",
        "model_path='/content/drive/MyDrive/Colab Notebooks/bi_best_model.keras' # modelin konumu\n",
        "model_test_path='/content/drive/MyDrive/Colab Notebooks/accuracy_calculation/unlabeled_test_data'# modelin testi için kullanılacak etiketsiz test verilerinin konumu\n",
        "model_test_path_labeled='/content/drive/MyDrive/Colab Notebooks/accuracy_calculation/labeled_test_data' # model testinin accuracy hesaplanması için kullanılacak etiketli verilerin konumu\n",
        "\n",
        "\n",
        "\n",
        "global words,wordsIndext\n",
        "\n",
        "words = []\n",
        "wordsIndext = []\n",
        "max_sequence_length = 384\n",
        "\n",
        "\n",
        "\n",
        "label_list = [\"<start_\\\"company_name\\\">\",\n",
        "              \"<end_\\\"company_name\\\">\",\n",
        "                  \"<start_\\\"date\\\">\",\n",
        "                  \"<end_\\\"date\\\">\",\n",
        "                  \"<start_\\\"time\\\">\",\n",
        "                  \"<end_\\\"time\\\">\",\n",
        "                  \"<start_\\\"receipt_number\\\">\",\n",
        "                  \"<end_\\\"receipt_number\\\">\",\n",
        "                  \"<start_\\\"tax\\\">\",\n",
        "                  \"<end_\\\"tax\\\">\",\n",
        "                  \"<start_\\\"amount\\\">\",\n",
        "                  \"<end_\\\"amount\\\">\"]\n",
        "\n",
        "label_list2= [\"Pad\",\"Others\",\"B_Comp\",\"l_Comp\",\"B_Date\",\"l_Date\",\"B_Time\",\"l_Time\",\n",
        "                  \"B_Receipt\",\"l_Receipt\",\"B_Tax\",\"l_Tax\",\"B_Amount\",\"l_Amount\"]\n",
        "\n",
        "\n",
        "#gonna be added as code\n",
        "global arrayOfAccuracyValues\n",
        "arrayOfAccuracyValues = [] #[\"correctTotal\",Total]\n",
        "\n",
        "for i,element in enumerate(label_list2):\n",
        "    if(i>0):\n",
        "        arrayOfAccuracyValues+=[[0,0,0,0,0]]\n",
        "print (arrayOfAccuracyValues)\n",
        "\n",
        "\n",
        "def splitfunction(text:str):\n",
        "    global words,wordsIndext\n",
        "    words = []\n",
        "    wordsIndext = []\n",
        "    texts = text.split()\n",
        "    for word in texts:\n",
        "        words.append(word)\n",
        "        wordsIndext.append(1)\n",
        "    for i in range(max_sequence_length-len(wordsIndext)):\n",
        "        wordsIndext.append(0)\n",
        "\n",
        "\n",
        "\n",
        "def indexAssignment(tag,last):\n",
        "    if(tag==None):\n",
        "        return None\n",
        "    index = label_list.index(tag)+2\n",
        "    if(last == \"l\"):\n",
        "       index +=1\n",
        "    return index\n",
        "\n",
        "\n",
        "def checkTag(word:str):\n",
        "    for tag in label_list:\n",
        "        index = word.find(tag)\n",
        "        if index != -1:\n",
        "            return tag\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def tagingWords():\n",
        "    control = None\n",
        "    counter = 0\n",
        "    for word in words:\n",
        "        tag = checkTag(word)\n",
        "        if tag != None:\n",
        "            if(word.find(\"<start_\") != -1):\n",
        "                control = tag\n",
        "            if(word.find(\"<start_\") != -1 and word.find(\"<end_\") == -1):\n",
        "                wordsIndext[counter] = indexAssignment(tag,\"B\")\n",
        "                counter+=1\n",
        "            elif(word.find(\"<start_\") != -1 and word.find(\"<end_\") != -1):\n",
        "                wordsIndext[counter] = indexAssignment(tag,\"B\")\n",
        "                counter+=1\n",
        "            else:\n",
        "                wordsIndext[counter] = indexAssignment(tag,\"B\")\n",
        "                counter+=1\n",
        "            if(word.find(\"<end_\") != -1):\n",
        "                control = None\n",
        "        elif control !=None:\n",
        "            wordsIndext[counter] = indexAssignment(control,\"l\")\n",
        "            counter+=1\n",
        "        else:\n",
        "            counter+=1\n",
        "\n",
        "\n",
        "def indexListFunction(texts):\n",
        "    splitfunction(texts)\n",
        "    tagingWords()\n",
        "    return wordsIndext\n",
        "\n",
        "\n",
        "folder_path_test =  model_test_path_labeled\n",
        "file_list_test = os.listdir(folder_path_test)\n",
        "accuracy_testing_data = []\n",
        "\n",
        "for file_name in file_list_test:\n",
        "    if file_name.endswith(\".txt\"):\n",
        "        file_path = os.path.join(folder_path_test, file_name)\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "            result = indexListFunction(text)\n",
        "            if len(accuracy_testing_data) == 0:\n",
        "                accuracy_testing_data = np.array([result])\n",
        "            else:\n",
        "                accuracy_testing_data = np.concatenate((accuracy_testing_data, [result]), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "#gonna be added as code\n",
        "def check_all_data_inreceipt_spesific_label(npArray,npArrayLabeled,labelIndex):\n",
        "    global arrayOfAccuracyValues\n",
        "    for i,element in enumerate(npArray):\n",
        "        if element == labelIndex:\n",
        "            arrayOfAccuracyValues[labelIndex-1][1]+=1\n",
        "            if(npArrayLabeled[i]==labelIndex):\n",
        "                arrayOfAccuracyValues[labelIndex-1][0]+=1     # doğru etiketlenenler\n",
        "            elif(npArrayLabeled[i]!=labelIndex and npArrayLabeled[i]==1):\n",
        "                arrayOfAccuracyValues[labelIndex-1][2]+=1     # yanlış etiketlenmiş ve other olanlar\n",
        "            elif(npArrayLabeled[i]!=labelIndex):\n",
        "                arrayOfAccuracyValues[labelIndex-1][3]+=1     # yanlış etiketlenmiş ve other olmayan\n",
        "\n",
        "\n",
        "\n",
        "global dataAccuracyArray\n",
        "dataAccuracyArray = [0 for _ in range(13)]\n",
        "\n",
        "def compute_data_accuracy_ratio():\n",
        "    for i,element in enumerate(arrayOfAccuracyValues):\n",
        "        if(element[1]!=0):\n",
        "            dataAccuracyArray[i] = round(element[0]/element[1],4)\n",
        "        else:\n",
        "            dataAccuracyArray[i] = 0.0\n",
        "\n",
        "\n",
        "def accuracy_calculation(etiketli_gercek_fis,model_tahmini_fis):\n",
        "    for i,element in enumerate(label_list2[1:]):\n",
        "        check_all_data_inreceipt_spesific_label(etiketli_gercek_fis, model_tahmini_fis, i+1)\n",
        "\n",
        "\n",
        "\n",
        "#MODELİ ÇALIŞTIR\n",
        "def model_run(directory):\n",
        "    all_texts = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "                txt_data = content.split()\n",
        "                all_texts.append(txt_data)\n",
        "\n",
        "\n",
        "    #TOKENIZER YÜKLE\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer_model = pickle.load(handle)\n",
        "\n",
        "\n",
        "    all_sequences=[]\n",
        "    for i in range(len(all_texts)):\n",
        "        all_sequences.append(tokenizer_model.texts_to_sequences(all_texts[i]))\n",
        "\n",
        "    max_word_length,trunc_type,padding_type = 20,'post','post'\n",
        "\n",
        "    all_padded_sequences=[]\n",
        "    for i in range(len(all_sequences)):\n",
        "        padded_sequence = pad_sequences(all_sequences[i], maxlen=max_word_length, padding=padding_type, truncating=trunc_type)\n",
        "        all_padded_sequences.append(padded_sequence)\n",
        "\n",
        "    padded_arrays = []\n",
        "    for arr in all_padded_sequences:\n",
        "        pad_width = ((0, max_sequence_length - len(arr)), (0, 0))\n",
        "        padded_arr = np.pad(arr, pad_width, mode='constant', constant_values=0)\n",
        "        padded_arrays.append(padded_arr)\n",
        "\n",
        "    xtrain=np.array(padded_arrays)\n",
        "    model = tensorflow.keras.models.load_model(model_path)\n",
        "\n",
        "    prediction=model.predict(xtrain)\n",
        "    #------------------------------------------------------------\n",
        "    label_list = [\"Pad\", \"Others\", \"B_Comp\", \"I_Comp\", \"B_Date\", \"I_Date\", \"B_Time\", \"I_Time\", \"B_Receipt\", \"I_Receipt\", \"B_Tax\", \"I_Tax\", \"B_Amount\", \"I_Amount\"]\n",
        "\n",
        "    predicted_labels = np.argmax(prediction, axis=-1)\n",
        "\n",
        "\n",
        "    # gonna be added\n",
        "    for i,element in enumerate(predicted_labels):\n",
        "        model_tahmini_fis=predicted_labels[i]\n",
        "        etiketli_gercek_fis = accuracy_testing_data[i]\n",
        "        accuracy_calculation(etiketli_gercek_fis,model_tahmini_fis)\n",
        "    compute_data_accuracy_ratio()\n",
        "\n",
        "    for i,element in enumerate(label_list):   # th değeri hesaplaması\n",
        "        if(i == 0):\n",
        "            continue\n",
        "        arrayOfAccuracyValues[i-1][4] = arrayOfAccuracyValues[i-1][1] - arrayOfAccuracyValues[i-1][0]\n",
        "\n",
        "    print(\"-------------------------------------------------------------------------------\")\n",
        "\n",
        "    for i,element in enumerate(label_list):\n",
        "        if(i == 0):\n",
        "            continue\n",
        "        print(f\"{element} : {dataAccuracyArray[i-1]}\") \n",
        "\n",
        "    print(\"-------------------------------------------------------------------------------\")\n",
        "\n",
        "    print(\"[Doğru bilinenler,   Tüm tahminler,     yanlış olup others olanlar,   yanlış olup others olmayanlar,     yanlış tahminler]\")\n",
        "\n",
        "\n",
        "    for i,element in enumerate(label_list):\n",
        "        if(i == 0):\n",
        "            continue\n",
        "        print(f\"{element} : {arrayOfAccuracyValues[i-1]}\")  # gerçek veri ile model çıktısının karşılaştırıp accuracy döndürür\n",
        "\n",
        "\n",
        "model_run(model_test_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
